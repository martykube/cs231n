{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marty loss 0.695316060767\n",
      "estimate 0.69314718056\n",
      "estimated gradient\n",
      "[[  4.77403092  -4.40043438  33.56160833]\n",
      " [ -4.77403092   4.40043438 -33.56160833]]\n",
      "analytic gradient\n",
      "[[  4.77403093  -4.40043411  33.56160882]\n",
      " [ -4.77403093   4.40043411 -33.56160882]]\n"
     ]
    }
   ],
   "source": [
    "# Vertical\n",
    "def loss_i(W, x, y):\n",
    "    \"\"\"\n",
    "    Calculate the loss for a single point\n",
    "    W CxD\n",
    "    x Dx1\n",
    "    y 1\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    f = W.dot(x)\n",
    "    f -= np.max(f)\n",
    "    loss = -f[y] + np.log(np.sum(np.exp(f)))\n",
    "    return loss\n",
    "\n",
    "def loss_n(W, X, y, reg):\n",
    "    \"\"\"\n",
    "    W CxD\n",
    "    x DxN\n",
    "    y N\n",
    "    \"\"\"\n",
    "    n_points = X.shape[1]\n",
    "    loss = 0\n",
    "    for point in range(n_points):\n",
    "        loss += loss_i(W, X[:, point], y[point])\n",
    "    loss /= n_points\n",
    "    loss += 0.5 * reg * np.sum(W * W)\n",
    "    return loss\n",
    "\n",
    "def loss_v(W, X, y, reg):\n",
    "    \"\"\"\n",
    "    W CxD\n",
    "    x DxN\n",
    "    y N\n",
    "    \"\"\"\n",
    "    n_points = X.shape[1]\n",
    "    F = W.dot(X)\n",
    "    F = F - np.max(F, axis=0)\n",
    "    loss = -np.sum(F[y, np.arange(n_points)]) \n",
    "    loss += np.sum(np.log(np.sum(np.exp(F), axis=0)))\n",
    "    loss /= n_points\n",
    "    loss += 0.5 * reg * np.sum(W * W)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def gradient_i(W, x, y, p):\n",
    "    \"\"\"\n",
    "    W CxD\n",
    "    x Dx1\n",
    "    y N\n",
    "    \"\"\"\n",
    "    f = W.dot(x)\n",
    "    f -= np.max(f)\n",
    "    dW = np.zeros_like(W)\n",
    "    # -xj\n",
    "    dW[y] -= x\n",
    "    sum_f = np.sum(np.exp(f))\n",
    "    for i in range(W.shape[0]):\n",
    "        for j in range(W.shape[1]):\n",
    "#            print \"%s, %s, %s\" % (p, i, j)\n",
    "#            print \"\\t%s, %s, %s\" % (F_exp[i, p], X[j, p], F_sum[p])\n",
    "            dW[i, j] += np.exp(f[i]) * x[j] / sum_f\n",
    "    return dW\n",
    "               \n",
    "def gradient_n(W, X, y, reg):\n",
    "    \"\"\"\n",
    "    W CxD\n",
    "    x DxN\n",
    "    y N\n",
    "    \"\"\"\n",
    "    dW = np.zeros_like(W)\n",
    "    n_points = X.shape[1]\n",
    "    for point in range(n_points):\n",
    "        dW += gradient_i(W, X[:, point], y[point], point)\n",
    "    dW /= n_points\n",
    "    dW += reg * W\n",
    "    return dW\n",
    "\n",
    "def gradient_v(W, X, y, reg):\n",
    "    \"\"\"\n",
    "    W CxD\n",
    "    x DxN\n",
    "    y N\n",
    "    \"\"\"\n",
    "    dW = np.zeros_like(W)\n",
    "    \n",
    "    # -xj\n",
    "    for i in range(dW.shape[0]):\n",
    "        dW[i] = -np.sum(X.T[y == i], axis=0)\n",
    "    \n",
    "    # Others\n",
    "    F = W.dot(X)\n",
    "    F -= np.max(F, axis=0)\n",
    "    F_exp = np.exp(F)\n",
    "    F_exp_over_sum = F_exp / np.sum(F_exp, axis=0)\n",
    "    dW += F_exp_over_sum.dot(X.T)\n",
    "    dW /= X.shape[1]\n",
    "\n",
    "    dW += reg * W\n",
    "    return dW\n",
    "\n",
    "reg = 0\n",
    "X = np.array([[101, 55, 88, 33], [27, 155, 37, 189], [200, 245, 88, 99]])\n",
    "y = np.array([1, 1, 0, 0])\n",
    "\n",
    "#X = np.array([[101], [27], [200]])\n",
    "#y = np.array([1])\n",
    "\n",
    "W = np.array([[ -1.31696361e-04,   1.05243860e-04,   6.73918614e-05],  \n",
    "              [  1.35716710e-05,  -1.03811763e-04,  -5.01638507e-05]])\n",
    " \n",
    "print \"marty loss\", loss_v(W, X, y, reg)\n",
    "print \"estimate\", -np.log(0.5)\n",
    "\n",
    "grad_estimate = np.zeros_like(W)\n",
    "h = 1e-5\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[1]):\n",
    "        oldval = W[i, j]\n",
    "        W[i, j] = oldval + h\n",
    "        fxph = loss_v(W, X, y, reg)\n",
    "        W[i, j] = oldval - h\n",
    "        fxmh = loss_v(W, X, y, reg)\n",
    "        W[i, j] = oldval\n",
    "        grad_estimate[i, j] = (fxph - fxmh) / (2 * h)\n",
    "\n",
    "print \"estimated gradient\\n\", grad_estimate\n",
    "        \n",
    "dW = gradient_v(W, X, y, reg)        \n",
    "print \"analytic gradient\\n\", dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct\n",
      "[[ 35.02403093  52.09956589  80.31160882]\n",
      " [ 34.22596907  49.90043411  77.68839118]]\n",
      "[[ 35.02403093  52.09956589  80.31160882]\n",
      " [ 34.22596907  49.90043411  77.68839118]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[101], [27], [200]])\n",
    "y = np.array([1])\n",
    "\n",
    "X = np.array([[101, 55, 88, 33], [27, 155, 37, 189], [200, 245, 88, 99]])\n",
    "y = np.array([1, 1, 0, 0])\n",
    "\n",
    "W = np.array([[ -1.31696361e-04,   1.05243860e-04,   6.73918614e-05],  \n",
    "              [  1.35716710e-05,  -1.03811763e-04,  -5.01638507e-05]])\n",
    "\n",
    "print \"correct\\n\", gradient_n(W, X, y, 0)\n",
    "\n",
    "F = W.dot(X)\n",
    "F -= np.max(F, axis=0)\n",
    "F_exp_over_sum = np.exp(F) / np.sum(F_exp, axis=0)\n",
    "dW = F_exp_over_sum.dot(X.T)\n",
    "dW /= X.shape[1]\n",
    "print dW\n",
    "\n",
    "\n",
    "#dW = np.zeros_like(W)\n",
    "#for p in range(X.shape[1]):\n",
    "#    for i in range(W.shape[0]):\n",
    "#        for j in range(W.shape[1]):\n",
    "#            dW[i, j] += F_exp_over_sum[i, p] * X[j, p]\n",
    "            \n",
    "#dW /= X.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500, 500, 500, 500, 500, 500, 500, 500, 500, 500]\n",
      "['tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "D = 500\n",
    "N = 1000\n",
    "C = 2\n",
    "\n",
    "D = np.random.randn(1000, 500)\n",
    "hidden_layer_sizes = [500]*10\n",
    "print hidden_layer_sizes\n",
    "print ['tanh'] * len(hidden_layer_sizes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
